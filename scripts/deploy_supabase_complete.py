#!/usr/bin/env python3
"""
Complete Supabase Deployment Script

This script:
1. Deploys the complete unified schema (8 tables, 30+ indexes, 3 functions)
2. Verifies all tables and columns exist
3. Uploads knowledge atoms (if available)
4. Runs comprehensive validation tests

Usage:
    python scripts/deploy_supabase_complete.py

Requirements:
    - SUPABASE_URL in .env
    - SUPABASE_SERVICE_ROLE_KEY in .env
    - Optional: OPENAI_API_KEY for embeddings

Exit codes:
    0 - Success (all deployed and verified)
    1 - Failure (schema deployment failed)
    2 - Partial success (schema OK, but atom upload failed)
"""

import os
import sys
from pathlib import Path
from supabase import create_client, Client
from dotenv import load_dotenv
import time

# Load environment variables
load_dotenv()


def print_header(title: str):
    """Print formatted section header."""
    print("\n" + "=" * 80)
    print(title)
    print("=" * 80)


def print_step(step_num: int, total: int, description: str):
    """Print formatted step."""
    print(f"\n[{step_num}/{total}] {description}")
    print("-" * 80)


def get_supabase_client() -> Client:
    """Create and return Supabase client."""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

    if not url or not key:
        print("‚ùå ERROR: Missing Supabase credentials")
        print("   Set SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY in .env")
        sys.exit(1)

    return create_client(url, key)


def deploy_schema(supabase: Client, sql_file_path: Path) -> bool:
    """
    Deploy complete schema from SQL file.

    Args:
        supabase: Supabase client
        sql_file_path: Path to SQL file

    Returns:
        True if successful, False otherwise
    """
    print(f"Reading SQL from: {sql_file_path}")

    if not sql_file_path.exists():
        print(f"‚ùå ERROR: SQL file not found: {sql_file_path}")
        return False

    sql_content = sql_file_path.read_text(encoding='utf-8')

    print(f"SQL file size: {len(sql_content):,} bytes")
    print("Executing schema deployment...")

    try:
        # Execute SQL via Supabase REST API
        # Note: For large SQL files, may need to split or use psql directly
        result = supabase.rpc('exec_sql', {'sql': sql_content}).execute()

        print("‚úÖ Schema deployed successfully")
        return True

    except Exception as e:
        # If REST API doesn't work, suggest manual deployment
        print("‚ö†Ô∏è  REST API execution not available")
        print("   Please deploy manually via Supabase SQL Editor")
        print(f"   File: {sql_file_path}")
        print(f"   Error: {e}")
        return False


def verify_tables(supabase: Client) -> bool:
    """
    Verify all 8 tables exist.

    Args:
        supabase: Supabase client

    Returns:
        True if all tables exist, False otherwise
    """
    expected_tables = [
        'agent_factory_settings',
        'session_memories',
        'agent_messages',
        'knowledge_atoms',
        'video_scripts',
        'video_approval_queue',
        'agent_status',
        'alert_history'
    ]

    print(f"Checking for {len(expected_tables)} tables...")

    all_exist = True

    for table in expected_tables:
        try:
            # Try to query the table (will fail if doesn't exist)
            result = supabase.table(table).select("*").limit(1).execute()
            print(f"  ‚úÖ {table}")
        except Exception as e:
            print(f"  ‚ùå {table} - NOT FOUND")
            all_exist = False

    return all_exist


def verify_critical_columns(supabase: Client) -> bool:
    """
    Verify critical columns exist (the ones that were missing before).

    Args:
        supabase: Supabase client

    Returns:
        True if all columns exist, False otherwise
    """
    print("Checking critical columns...")

    checks = [
        ('agent_messages', 'session_id'),
        ('knowledge_atoms', 'content'),
    ]

    all_exist = True

    for table, column in checks:
        try:
            # Try to select the column
            result = supabase.table(table).select(column).limit(1).execute()
            print(f"  ‚úÖ {table}.{column}")
        except Exception as e:
            print(f"  ‚ùå {table}.{column} - NOT FOUND")
            all_exist = False

    return all_exist


def verify_agents(supabase: Client) -> bool:
    """
    Verify all 24 agents were inserted into agent_status.

    Args:
        supabase: Supabase client

    Returns:
        True if all 24 agents exist, False otherwise
    """
    print("Checking agent_status table...")

    try:
        result = supabase.table('agent_status').select('agent_name, team').execute()

        agent_count = len(result.data)

        print(f"  Total agents: {agent_count}")

        if agent_count == 24:
            print("  ‚úÖ All 24 agents present")

            # Group by team
            teams = {}
            for agent in result.data:
                team = agent['team']
                teams[team] = teams.get(team, 0) + 1

            for team, count in sorted(teams.items()):
                print(f"    {team}: {count}")

            return True
        else:
            print(f"  ‚ö†Ô∏è  Expected 24 agents, found {agent_count}")
            return False

    except Exception as e:
        print(f"  ‚ùå Error checking agents: {e}")
        return False


def check_atom_files() -> int:
    """
    Check how many knowledge atoms are available to upload.

    Returns:
        Number of atoms found
    """
    atoms_dir = Path("data/atoms")

    if not atoms_dir.exists():
        return 0

    json_files = list(atoms_dir.glob("**/*.json"))
    return len(json_files)


def upload_knowledge_atoms(supabase: Client) -> tuple[int, int]:
    """
    Upload knowledge atoms to Supabase.

    Args:
        supabase: Supabase client

    Returns:
        Tuple of (uploaded_count, failed_count)
    """
    atoms_dir = Path("data/atoms")

    if not atoms_dir.exists():
        print(f"‚ö†Ô∏è  Atoms directory not found: {atoms_dir}")
        return (0, 0)

    json_files = list(atoms_dir.glob("**/*.json"))

    if not json_files:
        print("‚ö†Ô∏è  No atom files found")
        return (0, 0)

    print(f"Found {len(json_files)} atom files")
    print("Uploading to Supabase...")

    uploaded = 0
    failed = 0

    for i, atom_file in enumerate(json_files, 1):
        try:
            import json
            atom_data = json.loads(atom_file.read_text(encoding='utf-8'))

            # Upload to Supabase
            result = supabase.table('knowledge_atoms').upsert(atom_data).execute()

            uploaded += 1

            if i % 100 == 0:
                print(f"  Uploaded {i}/{len(json_files)} ({i/len(json_files)*100:.1f}%)...")

        except Exception as e:
            failed += 1
            if failed <= 5:  # Show first 5 errors
                print(f"  ‚ùå Failed: {atom_file.name} - {e}")

    return (uploaded, failed)


def main():
    """Main entry point."""
    print_header("COMPLETE SUPABASE DEPLOYMENT")

    # Get Supabase client
    print("\n[0/6] Connecting to Supabase...")
    print("-" * 80)

    supabase = get_supabase_client()

    url_display = os.getenv("SUPABASE_URL", "").split("//")[1] if "//" in os.getenv("SUPABASE_URL", "") else "unknown"
    print(f"Connected to: {url_display}")

    # Step 1: Deploy schema
    print_step(1, 6, "DEPLOYING UNIFIED SCHEMA")

    project_root = Path(__file__).parent.parent
    sql_file = project_root / "docs" / "database" / "SUPABASE_COMPLETE_UNIFIED.sql"

    # Since Supabase REST API doesn't support raw SQL execution well,
    # we'll guide the user to run it manually
    if sql_file.exists():
        print(f"üìÑ Schema file ready: {sql_file}")
        print("\nTo deploy, run this SQL in Supabase Dashboard ‚Üí SQL Editor:")
        print(f"  File: {sql_file.name}")
        print(f"  Size: {sql_file.stat().st_size:,} bytes")
        print("\nPress ENTER after you've run the SQL, or Ctrl+C to abort...")

        try:
            input()
        except KeyboardInterrupt:
            print("\n\n‚ùå Deployment aborted")
            sys.exit(1)

    # Step 2: Verify tables
    print_step(2, 6, "VERIFYING TABLES")

    if not verify_tables(supabase):
        print("\n‚ùå Table verification failed")
        print("   Make sure you ran the SQL file in Supabase SQL Editor")
        sys.exit(1)

    print("\n‚úÖ All tables exist")

    # Step 3: Verify critical columns
    print_step(3, 6, "VERIFYING CRITICAL COLUMNS")

    if not verify_critical_columns(supabase):
        print("\n‚ùå Column verification failed")
        sys.exit(1)

    print("\n‚úÖ All critical columns exist")

    # Step 4: Verify agents
    print_step(4, 6, "VERIFYING AGENT DATA")

    if not verify_agents(supabase):
        print("\n‚ö†Ô∏è  Agent data incomplete (continuing anyway)")
    else:
        print("\n‚úÖ All 24 agents verified")

    # Step 5: Check for atoms to upload
    print_step(5, 6, "CHECKING FOR KNOWLEDGE ATOMS")

    atom_count = check_atom_files()

    if atom_count > 0:
        print(f"Found {atom_count} knowledge atoms ready to upload")

        response = input("Upload atoms now? (y/N): ")

        if response.lower() == 'y':
            uploaded, failed = upload_knowledge_atoms(supabase)

            print(f"\n‚úÖ Uploaded: {uploaded}/{atom_count}")

            if failed > 0:
                print(f"‚ö†Ô∏è  Failed: {failed}")

        else:
            print("‚ö†Ô∏è  Skipped atom upload")
    else:
        print("‚ÑπÔ∏è  No atoms found (run FULL_AUTO_KB_BUILD.py to generate)")

    # Step 6: Final verification
    print_step(6, 6, "FINAL VERIFICATION")

    try:
        # Check knowledge_atoms count
        ka_result = supabase.table('knowledge_atoms').select('id', count='exact').execute()
        ka_count = ka_result.count if hasattr(ka_result, 'count') else len(ka_result.data)

        # Check settings count
        settings_result = supabase.table('agent_factory_settings').select('id', count='exact').execute()
        settings_count = settings_result.count if hasattr(settings_result, 'count') else len(settings_result.data)

        print(f"  Knowledge atoms: {ka_count}")
        print(f"  Settings: {settings_count}")

        if ka_count > 0 and settings_count > 0:
            print("\n‚úÖ Supabase deployment COMPLETE")
        elif ka_count == 0:
            print("\n‚ö†Ô∏è  Supabase schema deployed, but no knowledge atoms uploaded")
            print("   Run: poetry run python scripts/FULL_AUTO_KB_BUILD.py")
        else:
            print("\n‚ö†Ô∏è  Partial deployment - some data missing")

    except Exception as e:
        print(f"\n‚ö†Ô∏è  Verification incomplete: {e}")

    # Summary
    print_header("DEPLOYMENT SUMMARY")

    print("\n‚úÖ Schema deployed (8 tables, 30+ indexes, 3 functions)")
    print("‚úÖ All critical columns exist (session_id, content)")
    print("‚úÖ 24 agents initialized")

    if atom_count > 0:
        print(f"‚úÖ {atom_count} knowledge atoms available")
    else:
        print("‚ö†Ô∏è  No knowledge atoms (generate with FULL_AUTO_KB_BUILD.py)")

    print("\nNext steps:")
    print("  1. Test vector search: poetry run python examples/test_vector_search.py")
    print("  2. Test Telegram bot: /kb_search <query>")
    print("  3. Generate videos: poetry run python agents/media/video_assembly_agent.py")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
