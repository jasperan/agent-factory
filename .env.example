# AgentFactory Environment Variables
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# OpenAI (required for default configuration)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (optional - for Claude models)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google (optional - for Gemini models)
# GOOGLE_API_KEY=your_google_api_key_here

# =============================================================================
# Research Tools API Keys
# =============================================================================

# Tavily Search (optional - AI-optimized search)
# Get your API key at: https://tavily.com
# TAVILY_API_KEY=your_tavily_api_key_here

# =============================================================================
# Configuration Options
# =============================================================================

# Default LLM Provider (openai, anthropic, google)
DEFAULT_LLM_PROVIDER=openai

# Default Model
DEFAULT_MODEL=gpt-4o

# Default Temperature (0.0 - 1.0)
DEFAULT_TEMPERATURE=0.0

# Verbose Mode (true/false)
VERBOSE=true

# =============================================================================
# API Authentication (Phase 7)
# =============================================================================

# Agent Factory API Key (required for REST API endpoints)
# Generate with: poetry run python -c "import secrets; print(f'ak_dev_{secrets.token_hex(16)}')"
API_KEY=ak_dev_your_generated_key_here

# =============================================================================
# Telegram Bot Configuration
# =============================================================================

# Telegram Bot Token (required for Telegram bot)
# Get from @BotFather on Telegram: /newbot
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# Rate Limiting (optional)
TELEGRAM_RATE_LIMIT=10  # Messages per minute per user

# User Whitelist (optional - comma-separated chat IDs)
# Leave empty to allow all users
# TELEGRAM_ALLOWED_USERS=12345,67890

# Logging (optional)
# TELEGRAM_LOG_CONVERSATIONS=false  # GDPR: keep false in production

# =============================================================================
# Memory Storage (Supabase)
# =============================================================================

# Supabase PostgreSQL database (required for cloud memory storage)
# Get from: https://supabase.com/dashboard/project/_/settings/api
SUPABASE_URL=your_supabase_project_url_here
SUPABASE_KEY=your_supabase_anon_key_here

# Alternative: Use service_role key for admin operations (keep secret!)
# SUPABASE_KEY=your_supabase_service_role_key_here

# =============================================================================
# Ollama (FREE Local LLMs) - RECOMMENDED
# =============================================================================

# Enable FREE local LLMs instead of paid APIs (set to true)
USE_OLLAMA=true

# Ollama API endpoint (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Default Ollama model for coding tasks
# Options:
#   - deepseek-coder:6.7b (RECOMMENDED - fast, high quality, 8GB RAM)
#   - codellama:7b (good, 8GB RAM)
#   - llama3.1:8b (better reasoning, 12GB RAM)
#   - deepseek-coder:33b (GPT-4 level, 32GB RAM + GPU)
OLLAMA_MODEL=deepseek-coder:6.7b

# Setup Instructions:
#   1. Install Ollama: winget install Ollama.Ollama
#   2. Pull model: ollama pull deepseek-coder:6.7b
#   3. Set USE_OLLAMA=true above
#   4. Run tasks for FREE! (no API costs)
#
# See: docs/OPENHANDS_FREE_LLM_GUIDE.md for complete setup guide

# =============================================================================
# GitHub Issue Automation (Optional)
# =============================================================================

# Automatically solve GitHub issues with FREE Ollama
# See: docs/GITHUB_ISSUE_AUTOMATION.md for complete guide

# Labels to auto-solve (comma-separated)
# Example: GITHUB_AUTO_SOLVE_LABELS=agent-task,good first issue,documentation
# GITHUB_AUTO_SOLVE_LABELS=

# Auto-approve solutions (DANGEROUS - use with caution!)
# Set to 'true' only for trusted, simple issues
# Default: false (requires manual approval)
GITHUB_AUTO_APPROVE=false

# Auto-push after commit
# Set to 'true' to automatically push to GitHub
# Default: false (asks before pushing)
GITHUB_AUTO_PUSH=false

# Default timeout for issue solving (seconds)
# Increase for complex issues or slower models
# Default: 300 (5 minutes)
GITHUB_SOLVE_TIMEOUT=300

# =============================================================================
# Advanced Options
# =============================================================================

# LangSmith (optional - for debugging and monitoring)
# Get your API key at: https://smith.langchain.com
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your_langsmith_api_key_here
# LANGCHAIN_PROJECT=agent-factory

# =============================================================================
# Notes
# =============================================================================
#
# Free Tools (no API key required):
# - Wikipedia Search
# - DuckDuckGo Search
# - File operations (read, write, list, search)
# - Git operations
# - Current time
#
# Paid/API Key Required:
# - OpenAI (ChatGPT) - https://platform.openai.com/api-keys
# - Anthropic (Claude) - https://console.anthropic.com/
# - Google (Gemini) - https://makersuite.google.com/app/apikey
# - Tavily Search - https://tavily.com
#
